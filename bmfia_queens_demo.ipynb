{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fd5345",
   "metadata": {},
   "source": [
    "## Setup of QUEENS based models, schedulers and drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff7f0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to external computational models and directories\n",
    "from pathlib import Path\n",
    "\n",
    "## Paths to model input files\n",
    "lf_input_file_template = Path(\"./external_models/lf_input_template.json\")\n",
    "lf_adjoint_input_file_template = Path(\n",
    "    \"./external_models/lf_adjoint_input_template.json\"\n",
    ")\n",
    "hf_input_file_template = Path(\"./external_models/hf_input_template.json\")\n",
    "\n",
    "## Paths to model executables\n",
    "lf_model_path = Path(\"./external_models/darcy\")\n",
    "lf_adjoint_model_path = Path(\"./external_models/darcy_adjoint\")\n",
    "hf_model_path = Path(\"./external_models/darcy\")\n",
    "\n",
    "## Path to output directory\n",
    "output_dir_path = Path(\"./output\")\n",
    "output_dir_path_initial_training = output_dir_path / \"initial_training_phase\"\n",
    "output_dir_path_inference = output_dir_path / \"inference_phase\"\n",
    "\n",
    "## quick check if all these paths exist\n",
    "assert (\n",
    "    lf_input_file_template.exists()\n",
    "), \"Low-fidelity input file template does not exist.\"\n",
    "assert (\n",
    "    lf_adjoint_input_file_template.exists()\n",
    "), \"Low-fidelity adjoint input file template does not exist.\"\n",
    "assert (\n",
    "    hf_input_file_template.exists()\n",
    "), \"High-fidelity input file template does not exist.\"\n",
    "assert lf_model_path.exists(), \"Low-fidelity model executable does not exist.\"\n",
    "assert (\n",
    "    lf_adjoint_model_path.exists()\n",
    "), \"Low-fidelity adjoint model executable does not exist.\"\n",
    "assert hf_model_path.exists(), \"High-fidelity model executable does not exist.\"\n",
    "assert output_dir_path.exists(), \"Output directory does not exist.\"\n",
    "assert (\n",
    "    output_dir_path_initial_training.exists()\n",
    "), \"Output directory for initial training phase does not exist.\"\n",
    "assert (\n",
    "    output_dir_path_inference.exists()\n",
    "), \"Output directory for inference phase does not exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37072ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "|                                        MeanFieldNormal                                        |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -|\n",
      "| self      : <queens.distributions.mean_field_normal.MeanFieldNormal object at 0x7fdcc47b9950> |\n",
      "| mean      : 0                                                                                 |\n",
      "| variance  : 1                                                                                 |\n",
      "| dimension : 1000                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+-------------------------------------------------------------------------------------------+\n",
      "|                                        Parameters                                         |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -|\n",
      "| self  : <queens.parameters.parameters.Parameters object at 0x7fdcc4350c90>                |\n",
      "| x_vec : <queens.distributions.mean_field_normal.MeanFieldNormal object at 0x7fdcc47b9950> |\n",
      "+-------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|                                               NumpyFile                                                |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - |\n",
      "| self                          : <queens.data_processors.numpy_file.NumpyFile object at 0x7fdccefdf9d0> |\n",
      "| file_name_identifier          : '_sol.npy'                                                             |\n",
      "| file_options_dict             : {'delete_field_data': False}                                           |\n",
      "| files_to_be_deleted_regex_lst : None                                                                   |\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|                                               NumpyFile                                                |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - |\n",
      "| self                          : <queens.data_processors.numpy_file.NumpyFile object at 0x7fdcc42b3e50> |\n",
      "| file_name_identifier          : '_sol.npy'                                                             |\n",
      "| file_options_dict             : {'delete_field_data': False}                                           |\n",
      "| files_to_be_deleted_regex_lst : None                                                                   |\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|                                               Mpi                                                |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - |\n",
      "| self                    : <queens.drivers.mpi.Mpi object at 0x7fdcc6bc7290>                      |\n",
      "| parameters              : <queens.parameters.parameters.Parameters object at 0x7fdcc4350c90>     |\n",
      "| input_templates         : PosixPath('external_models/lf_input_template.json')                    |\n",
      "| executable              : PosixPath('external_models/darcy')                                     |\n",
      "| files_to_copy           : None                                                                   |\n",
      "| data_processor          : <queens.data_processors.numpy_file.NumpyFile object at 0x7fdccefdf9d0> |\n",
      "| gradient_data_processor : None                                                                   |\n",
      "| mpi_cmd                 : '/usr/bin/mpirun --bind-to none'                                       |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                            Mpi                                                             |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - |\n",
      "| self                             : <queens.drivers.mpi.Mpi object at 0x7fdcc6bc7290>                                       |\n",
      "| parameters                       : <queens.parameters.parameters.Parameters object at 0x7fdcc4350c90>                      |\n",
      "| input_templates                  : PosixPath('external_models/lf_input_template.json')                                     |\n",
      "| jobscript_template               : '{{ mpi_cmd }} -np {{ num_procs }} {{ executable }} {{ input_file }} {{ output_file }}' |\n",
      "| executable                       : PosixPath('external_models/darcy')                                                      |\n",
      "| files_to_copy                    : None                                                                                    |\n",
      "| data_processor                   : <queens.data_processors.numpy_file.NumpyFile object at 0x7fdccefdf9d0>                  |\n",
      "| gradient_data_processor          : None                                                                                    |\n",
      "| jobscript_file_name              : 'jobscript.sh'                                                                          |\n",
      "| extra_options                    : {'mpi_cmd': '/usr/bin/mpirun --bind-to none'}                                           |\n",
      "| raise_error_on_jobscript_failure : True                                                                                    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|                                               Mpi                                                |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - |\n",
      "| self                    : <queens.drivers.mpi.Mpi object at 0x7fdcc416dd90>                      |\n",
      "| parameters              : <queens.parameters.parameters.Parameters object at 0x7fdcc4350c90>     |\n",
      "| input_templates         : PosixPath('external_models/hf_input_template.json')                    |\n",
      "| executable              : PosixPath('external_models/darcy')                                     |\n",
      "| files_to_copy           : None                                                                   |\n",
      "| data_processor          : <queens.data_processors.numpy_file.NumpyFile object at 0x7fdcc42b3e50> |\n",
      "| gradient_data_processor : None                                                                   |\n",
      "| mpi_cmd                 : '/usr/bin/mpirun --bind-to none'                                       |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                            Mpi                                                             |\n",
      "|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - |\n",
      "| self                             : <queens.drivers.mpi.Mpi object at 0x7fdcc416dd90>                                       |\n",
      "| parameters                       : <queens.parameters.parameters.Parameters object at 0x7fdcc4350c90>                      |\n",
      "| input_templates                  : PosixPath('external_models/hf_input_template.json')                                     |\n",
      "| jobscript_template               : '{{ mpi_cmd }} -np {{ num_procs }} {{ executable }} {{ input_file }} {{ output_file }}' |\n",
      "| executable                       : PosixPath('external_models/darcy')                                                      |\n",
      "| files_to_copy                    : None                                                                                    |\n",
      "| data_processor                   : <queens.data_processors.numpy_file.NumpyFile object at 0x7fdcc42b3e50>                  |\n",
      "| gradient_data_processor          : None                                                                                    |\n",
      "| jobscript_file_name              : 'jobscript.sh'                                                                          |\n",
      "| extra_options                    : {'mpi_cmd': '/usr/bin/mpirun --bind-to none'}                                           |\n",
      "| raise_error_on_jobscript_failure : True                                                                                    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial training phase of BMFIA\n",
    "## Import all necessary modules from QUEENS to setup models, drivers and schedulers\n",
    "from queens.global_settings import GlobalSettings\n",
    "from queens.data_processors.numpy_file import NumpyFile as NumpyDataProc\n",
    "from queens.drivers.mpi import Mpi as MpiDriver\n",
    "from queens.schedulers.local import Local as LocalScheduler\n",
    "from queens.models.simulation import Simulation as SimulationModel\n",
    "from queens.parameters import Parameters\n",
    "from queens.distributions.mean_field_normal import MeanFieldNormal\n",
    "from bmfia.bmfia_iterator import BmfiaIterator\n",
    "from queens.main import run_iterator\n",
    "\n",
    "## Setup global settings\n",
    "experiment_name = \"bmfia_initial_training_phase\"\n",
    "global_settings_initial = GlobalSettings(\n",
    "    experiment_name=experiment_name, output_dir=output_dir_path_initial_training\n",
    ")\n",
    "\n",
    "## Setup the parameter definition for the models\n",
    "x_vec = MeanFieldNormal(0, 1, 1000)  # TODO: exchange this for actual GMRF distribution\n",
    "parameters = Parameters(x_vec=x_vec)\n",
    "\n",
    "## Setup data processors, the velocity field is here additionally stored in a numpy file\n",
    "## with file name ending \"_sol.npy\"\n",
    "lf_data_processor = NumpyDataProc(\n",
    "    file_name_identifier=\"_sol.npy\", file_options_dict={\"delete_field_data\": False}\n",
    ")\n",
    "hf_data_processor = NumpyDataProc(\n",
    "    file_name_identifier=\"_sol.npy\", file_options_dict={\"delete_field_data\": False}\n",
    ")\n",
    "\n",
    "## Setup drivers\n",
    "mpi_driver_lf = MpiDriver(\n",
    "    parameters,\n",
    "    lf_input_file_template,\n",
    "    lf_model_path,\n",
    "    files_to_copy=None,\n",
    "    data_processor=lf_data_processor,\n",
    "    gradient_data_processor=None,\n",
    "    mpi_cmd=\"/usr/bin/mpirun --bind-to none\",\n",
    ")\n",
    "mpi_driver_hf = MpiDriver(\n",
    "    parameters,\n",
    "    hf_input_file_template,\n",
    "    hf_model_path,\n",
    "    files_to_copy=None,\n",
    "    data_processor=hf_data_processor,\n",
    "    gradient_data_processor=None,\n",
    "    mpi_cmd=\"/usr/bin/mpirun --bind-to none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc50e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 20:26:52,205 - distributed.scheduler - INFO - State start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 20:26:52,210 - distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,210 - distributed.scheduler - INFO -   dashboard at:  http://127.0.0.1:8787/status\n",
      "2025-08-26 20:26:52,211 - distributed.scheduler - INFO - Registering Worker plugin shuffle\n",
      "2025-08-26 20:26:52,235 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44327'\n",
      "2025-08-26 20:26:52,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34851'\n",
      "2025-08-26 20:26:52,239 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43893'\n",
      "2025-08-26 20:26:52,244 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39077'\n",
      "2025-08-26 20:26:52,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32813'\n",
      "2025-08-26 20:26:52,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38749'\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35067\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35067\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO -           Worker name:                          1\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43749\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r9v681a2\n",
      "2025-08-26 20:26:52,622 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34807\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34807\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO -           Worker name:                          2\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33669\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lh4lm1u7\n",
      "2025-08-26 20:26:52,633 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,634 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:35067 name: 1\n",
      "2025-08-26 20:26:52,634 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35067\n",
      "2025-08-26 20:26:52,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54254\n",
      "2025-08-26 20:26:52,635 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:52,635 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,635 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,636 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37581\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37581\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO -           Worker name:                          4\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34157\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g9e20alt\n",
      "2025-08-26 20:26:52,637 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34739\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34739\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO -           Worker name:                          3\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46383\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-07d53hgg\n",
      "2025-08-26 20:26:52,646 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,649 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:37581 name: 4\n",
      "2025-08-26 20:26:52,650 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37581\n",
      "2025-08-26 20:26:52,650 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54270\n",
      "2025-08-26 20:26:52,650 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:52,651 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,651 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,653 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:34807 name: 2\n",
      "2025-08-26 20:26:52,653 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34807\n",
      "2025-08-26 20:26:52,654 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54266\n",
      "2025-08-26 20:26:52,654 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:52,654 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,654 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,655 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38449\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38449\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO -           Worker name:                          0\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42733\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jphayxlk\n",
      "2025-08-26 20:26:52,661 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,663 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:34739 name: 3\n",
      "2025-08-26 20:26:52,664 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34739\n",
      "2025-08-26 20:26:52,664 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54272\n",
      "2025-08-26 20:26:52,664 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:52,665 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,665 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,665 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,674 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:38449 name: 0\n",
      "2025-08-26 20:26:52,674 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38449\n",
      "2025-08-26 20:26:52,675 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:52,675 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54278\n",
      "2025-08-26 20:26:52,675 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,675 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,675 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39613\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39613\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO -           Worker name:                          5\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44545\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vn4cn274\n",
      "2025-08-26 20:26:52,686 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,697 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:39613 name: 5\n",
      "2025-08-26 20:26:52,698 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39613\n",
      "2025-08-26 20:26:52,698 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54288\n",
      "2025-08-26 20:26:52,698 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:52,698 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,698 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:52,699 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43289\n",
      "2025-08-26 20:26:52,721 - distributed.scheduler - INFO - Receive client connection: Client-3cf48242-82aa-11f0-9d92-309c2365917f\n",
      "2025-08-26 20:26:52,722 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54292\n",
      "/home/nitzler/Programs/mambaforge/envs/queens/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41879 instead\n",
      "  warnings.warn(\n",
      "2025-08-26 20:26:52,735 - distributed.scheduler - INFO - State start\n",
      "2025-08-26 20:26:52,740 - distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:52,741 - distributed.scheduler - INFO -   dashboard at:  http://127.0.0.1:41879/status\n",
      "2025-08-26 20:26:52,741 - distributed.scheduler - INFO - Registering Worker plugin shuffle\n",
      "2025-08-26 20:26:52,763 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37817'\n",
      "2025-08-26 20:26:52,764 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34801'\n",
      "2025-08-26 20:26:52,767 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35037'\n",
      "2025-08-26 20:26:52,772 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44325'\n",
      "2025-08-26 20:26:52,776 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35453'\n",
      "2025-08-26 20:26:52,781 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38229'\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40837\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40837\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO -           Worker name:                          3\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33053\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:53,134 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0uuiijqz\n",
      "2025-08-26 20:26:53,135 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46449\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46449\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -           Worker name:                          0\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39819\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f3p6m68d\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44369\n",
      "2025-08-26 20:26:53,136 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44369\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO -           Worker name:                          2\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36029\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ljkc4lnz\n",
      "2025-08-26 20:26:53,137 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,138 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46507\n",
      "2025-08-26 20:26:53,138 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46507\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO -           Worker name:                          4\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35703\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-165d25dh\n",
      "2025-08-26 20:26:53,139 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,146 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:40837 name: 3\n",
      "2025-08-26 20:26:53,147 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40837\n",
      "2025-08-26 20:26:53,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41240\n",
      "2025-08-26 20:26:53,147 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:53,148 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,148 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,151 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:46449 name: 0\n",
      "2025-08-26 20:26:53,151 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46449\n",
      "2025-08-26 20:26:53,152 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41248\n",
      "2025-08-26 20:26:53,152 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:53,152 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,152 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,153 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,153 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:46507 name: 4\n",
      "2025-08-26 20:26:53,154 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46507\n",
      "2025-08-26 20:26:53,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41266\n",
      "2025-08-26 20:26:53,155 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:53,156 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:44369 name: 2\n",
      "2025-08-26 20:26:53,155 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,155 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,156 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,156 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44369\n",
      "2025-08-26 20:26:53,157 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41254\n",
      "2025-08-26 20:26:53,157 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:53,157 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,157 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33709\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33709\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO -           Worker name:                          1\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34629\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5dmj71h0\n",
      "2025-08-26 20:26:53,158 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,158 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,173 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:33709 name: 1\n",
      "2025-08-26 20:26:53,174 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33709\n",
      "2025-08-26 20:26:53,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41278\n",
      "2025-08-26 20:26:53,174 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:53,175 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,175 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,175 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46791\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46791\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO -           Worker name:                          5\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37535\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO -               Threads:                          1\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO -                Memory:                   5.22 GiB\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z99ed7lr\n",
      "2025-08-26 20:26:53,184 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,196 - distributed.scheduler - INFO - Register worker addr: tcp://127.0.0.1:46791 name: 5\n",
      "2025-08-26 20:26:53,197 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46791\n",
      "2025-08-26 20:26:53,197 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41284\n",
      "2025-08-26 20:26:53,197 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-08-26 20:26:53,198 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,198 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-08-26 20:26:53,198 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38337\n",
      "2025-08-26 20:26:53,251 - distributed.scheduler - INFO - Receive client connection: Client-3d451151-82aa-11f0-9d92-309c2365917f\n",
      "2025-08-26 20:26:53,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41286\n",
      "2025-08-26 20:26:53,362 - distributed.scheduler - INFO - Retire worker addresses (stimulus_id='retire-workers-1756232813.362589') (0, 1, 2, 3, 4, 5)\n",
      "2025-08-26 20:26:53,364 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44327'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,364 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,365 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34851'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,366 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38449. Reason: nanny-close\n",
      "2025-08-26 20:26:53,367 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,367 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,368 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43893'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,368 - distributed.core - INFO - Connection to tcp://127.0.0.1:43289 has been closed.\n",
      "2025-08-26 20:26:53,368 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35067. Reason: nanny-close\n",
      "2025-08-26 20:26:53,369 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,369 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,369 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,370 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39077'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,370 - distributed.core - INFO - Connection to tcp://127.0.0.1:43289 has been closed.\n",
      "2025-08-26 20:26:53,371 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34807. Reason: nanny-close\n",
      "2025-08-26 20:26:53,371 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,371 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,373 - distributed.core - INFO - Connection to tcp://127.0.0.1:43289 has been closed.\n",
      "2025-08-26 20:26:53,373 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,374 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32813'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,374 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,375 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34739. Reason: nanny-close\n",
      "2025-08-26 20:26:53,376 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,375 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,376 - distributed.core - INFO - Connection to tcp://127.0.0.1:43289 has been closed.\n",
      "2025-08-26 20:26:53,378 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38749'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,378 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,378 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37581. Reason: nanny-close\n",
      "2025-08-26 20:26:53,379 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,379 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,380 - distributed.core - INFO - Connection to tcp://127.0.0.1:43289 has been closed.\n",
      "2025-08-26 20:26:53,382 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,382 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39613. Reason: nanny-close\n",
      "2025-08-26 20:26:53,382 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,384 - distributed.core - INFO - Connection to tcp://127.0.0.1:43289 has been closed.\n",
      "2025-08-26 20:26:53,385 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,387 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54278; closing.\n",
      "2025-08-26 20:26:53,389 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54254; closing.\n",
      "2025-08-26 20:26:53,391 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54266; closing.\n",
      "2025-08-26 20:26:53,392 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54272; closing.\n",
      "2025-08-26 20:26:53,396 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54270; closing.\n",
      "2025-08-26 20:26:53,399 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:38449 name: 0 (stimulus_id='handle-worker-cleanup-1756232813.399016')\n",
      "2025-08-26 20:26:53,401 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:35067 name: 1 (stimulus_id='handle-worker-cleanup-1756232813.4016483')\n",
      "2025-08-26 20:26:53,404 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:34807 name: 2 (stimulus_id='handle-worker-cleanup-1756232813.4045675')\n",
      "2025-08-26 20:26:53,406 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:34739 name: 3 (stimulus_id='handle-worker-cleanup-1756232813.4065692')\n",
      "2025-08-26 20:26:53,413 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:37581 name: 4 (stimulus_id='handle-worker-cleanup-1756232813.4131293')\n",
      "2025-08-26 20:26:53,415 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54288; closing.\n",
      "2025-08-26 20:26:53,424 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:39613 name: 5 (stimulus_id='handle-worker-cleanup-1756232813.4248059')\n",
      "2025-08-26 20:26:53,427 - distributed.scheduler - INFO - Lost all workers\n",
      "2025-08-26 20:26:53,439 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:43289 remote=tcp://127.0.0.1:54288>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nitzler/Programs/mambaforge/envs/queens/lib/python3.11/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/home/nitzler/Programs/mambaforge/envs/queens/lib/python3.11/site-packages/tornado/gen.py\", line 783, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitzler/Programs/mambaforge/envs/queens/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 263, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2025-08-26 20:26:53,530 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:34851' closed.\n",
      "2025-08-26 20:26:53,533 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:44327' closed.\n",
      "2025-08-26 20:26:53,538 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:43893' closed.\n",
      "2025-08-26 20:26:53,540 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:32813' closed.\n",
      "2025-08-26 20:26:53,540 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:39077' closed.\n",
      "2025-08-26 20:26:53,543 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:38749' closed.\n",
      "2025-08-26 20:26:53,544 - distributed.scheduler - INFO - Closing scheduler. Reason: unknown\n",
      "2025-08-26 20:26:53,545 - distributed.scheduler - INFO - Scheduler closing all comms\n",
      "2025-08-26 20:26:53,649 - distributed.scheduler - INFO - Retire worker addresses (stimulus_id='retire-workers-1756232813.6490283') (0, 1, 2, 3, 4, 5)\n",
      "2025-08-26 20:26:53,650 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37817'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,651 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,653 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34801'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,653 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46449. Reason: nanny-close\n",
      "2025-08-26 20:26:53,654 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,655 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35037'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,656 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,656 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33709. Reason: nanny-close\n",
      "2025-08-26 20:26:53,656 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,657 - distributed.core - INFO - Connection to tcp://127.0.0.1:38337 has been closed.\n",
      "2025-08-26 20:26:53,658 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,658 - distributed.core - INFO - Connection to tcp://127.0.0.1:38337 has been closed.\n",
      "2025-08-26 20:26:53,659 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44325'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,659 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,661 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,660 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,661 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44369. Reason: nanny-close\n",
      "2025-08-26 20:26:53,662 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,663 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35453'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,663 - distributed.core - INFO - Connection to tcp://127.0.0.1:38337 has been closed.\n",
      "2025-08-26 20:26:53,664 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40837. Reason: nanny-close\n",
      "2025-08-26 20:26:53,664 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,665 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,667 - distributed.core - INFO - Connection to tcp://127.0.0.1:38337 has been closed.\n",
      "2025-08-26 20:26:53,669 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,669 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,672 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38229'. Reason: nanny-close\n",
      "2025-08-26 20:26:53,673 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46507. Reason: nanny-close\n",
      "2025-08-26 20:26:53,674 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,675 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2025-08-26 20:26:53,677 - distributed.core - INFO - Connection to tcp://127.0.0.1:38337 has been closed.\n",
      "2025-08-26 20:26:53,683 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41248; closing.\n",
      "2025-08-26 20:26:53,681 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,687 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41278; closing.\n",
      "2025-08-26 20:26:53,690 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41254; closing.\n",
      "2025-08-26 20:26:53,690 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46791. Reason: nanny-close\n",
      "2025-08-26 20:26:53,691 - distributed.worker - INFO - Removing Worker plugin shuffle\n",
      "2025-08-26 20:26:53,694 - distributed.core - INFO - Connection to tcp://127.0.0.1:38337 has been closed.\n",
      "2025-08-26 20:26:53,696 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41240; closing.\n",
      "2025-08-26 20:26:53,700 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41266; closing.\n",
      "2025-08-26 20:26:53,700 - distributed.nanny - INFO - Worker closed\n",
      "2025-08-26 20:26:53,707 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:46449 name: 0 (stimulus_id='handle-worker-cleanup-1756232813.707727')\n",
      "2025-08-26 20:26:53,717 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:33709 name: 1 (stimulus_id='handle-worker-cleanup-1756232813.7176118')\n",
      "2025-08-26 20:26:53,724 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:44369 name: 2 (stimulus_id='handle-worker-cleanup-1756232813.724074')\n",
      "2025-08-26 20:26:53,728 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:40837 name: 3 (stimulus_id='handle-worker-cleanup-1756232813.7288108')\n",
      "2025-08-26 20:26:53,741 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:46507 name: 4 (stimulus_id='handle-worker-cleanup-1756232813.741295')\n",
      "2025-08-26 20:26:53,783 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41284; closing.\n",
      "2025-08-26 20:26:53,789 - distributed.scheduler - INFO - Remove worker addr: tcp://127.0.0.1:46791 name: 5 (stimulus_id='handle-worker-cleanup-1756232813.789344')\n",
      "2025-08-26 20:26:53,790 - distributed.scheduler - INFO - Lost all workers\n",
      "2025-08-26 20:26:53,861 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:34801' closed.\n",
      "2025-08-26 20:26:53,875 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:37817' closed.\n",
      "2025-08-26 20:26:53,880 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:35037' closed.\n",
      "2025-08-26 20:26:53,885 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:44325' closed.\n",
      "2025-08-26 20:26:53,887 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:35453' closed.\n",
      "2025-08-26 20:26:53,888 - distributed.nanny - INFO - Nanny at 'tcp://127.0.0.1:38229' closed.\n",
      "2025-08-26 20:26:53,889 - distributed.scheduler - INFO - Closing scheduler. Reason: unknown\n",
      "2025-08-26 20:26:53,890 - distributed.scheduler - INFO - Scheduler closing all comms\n"
     ]
    }
   ],
   "source": [
    "# build the schedulers and the rest of the QUEENS model in context\n",
    "# this makes sure that everything is closed properly at the end\n",
    "# here we actually run the QUEENS run / the initial training phase of BMFIA\n",
    "with global_settings_initial:\n",
    "    \n",
    "    ## Setup schedulers with local MPI scheduler; allow 6 jobs to run in parallel on one processor each\n",
    "    local_scheduler_lf = LocalScheduler(\n",
    "        experiment_name, num_jobs=6, num_procs=1, restart_workers=False, verbose=True\n",
    "    )\n",
    "    local_scheduler_hf = LocalScheduler(\n",
    "        experiment_name, num_jobs=6, num_procs=1, restart_workers=False, verbose=True\n",
    "    )\n",
    "\n",
    "    ## Setup the QUEENS simulation models\n",
    "    lf_model = SimulationModel(scheduler=local_scheduler_lf, driver=mpi_driver_lf)\n",
    "    hf_model = SimulationModel(scheduler=local_scheduler_hf, driver=mpi_driver_hf)\n",
    "\n",
    "    ## Setup the BMFIA iterator\n",
    "    bmfia_iterator = BmfiaIterator()\n",
    "\n",
    "    ## finally run the BMFIA iterator (the initial training phase) / start the QUEENS run\n",
    "    run_iterator(bmfia_iterator, global_settings=global_settings_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e9200",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "queens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
